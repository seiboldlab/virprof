Env(name="virprof_r", base="bioconda",
    packages=[
        "r-magrittr",
        "r-dplyr",
        "r-readr",
        "r-purrr",
        "r-tidyr",
        "r-stringr",
        "r-fuzzyjoin",
        "r-tibble",
        "r-openxlsx",
        "r-optparse",
        "r-tidyverse",
        "r-patchwork",
        "r-ggrepel",
        "r-here",
        "bioconductor-iranges",
        "bedtools",
        "r-rentrez",
        "r-ggnewscale",
    ])

Env(name="virprof_py", base="bioconda",
    packages=[
        "python>=3.10",
        "graph-tool >=2.34",
        "biopython",
        "click",
        "tqdm",
        "networkx > 2",
        "requests",
    ])

BIN = srcdir("../bin/")


with Stage("get_unmapped_vp") as S:
    S.require(
        data = [["bam"], ["salmon/aux_info/unmapped_names.txt"]],
        fq = [["R1.fq.gz", "R2.fq.gz"]],
    )
    rule vp_unmapped_from_bam:
        message:
            "{:name:}: {input.bam}"
        input:
            bam =  "{:prev:}/{target}.bam"
        output:
            fq1 = temp("{:this:}/{target}.{:pairnames[0]:}.fq.gz"),
            fq2 = temp("{:this:}/{target}.{:pairnames[1]:}.fq.gz"),
        log:
            "{:this:}/{target}.log"
        benchmark:
            "benchmarks/{:name:}/{:this:}/{target}.txt"
        threads:
            4
        resources:
            mem = "8g"
        params:
            f = 12,
            F = 0x900,
            G = 0,
        conda:
            "samtools"
        shell:
            "samtools fastq"
            " -1 {output.fq1}"
            " -2 {output.fq2}"
            " --threads {threads}"
            " -f {params.f}"
            " -F {params.F}"
            " -G {params.G}"
            " {input}"
            " 2>&1 >{log}"

    rule vp_unmapped_from_salmon:
        message:
            "{:name:}: {output.fq1} from Salmon unmapped names"
        input:
            fq1 = "{:prev:}/{target}.{:pairnames[0]:}.fq.gz",
            fq2 = "{:prev:}/{target}.{:pairnames[1]:}.fq.gz",
            unmapped = "{:prev:}/{target}.salmon/aux_info/unmapped_names.txt",
        output:
            fq1 = temp("{:this:}/{target}.{:pairnames[0]:}.fq.gz"),
            fq2 = temp("{:this:}/{target}.{:pairnames[1]:}.fq.gz"),
        log:
            "{:this:}/{target}.log"
        benchmark:
            "benchmarks/{:name:}/{:this:}/{target}.txt"
        threads:
            8
        resources:
            mem="120g" # 80g sufficed for <48GB/fq.gz
        params:
            pattern = "u"
        conda:
            "bbmap"
        shell:
            "exec >{log} 2>&1;"
            "echo Grabbing {params.pattern} from {input.unmapped};"
            "echo and extracting from {input.fq1} and {input.fq2};"
            "if grep -ql '{params.pattern}$' {input.unmapped}; then"
            "  grep '{params.pattern}$' {input.unmapped} |"
            "    cut -d' ' -f1 |"
            "    filterbyname.sh"
            "      -Xmx{resources.mem_mb}m"
            "      in={input.fq1}"
            "      in2={input.fq2}"
            "      out={output.fq1}"
            "      out2={output.fq2}"
            "      names=/dev/stdin"
            "      include=t"
            "      -Xmx{resources.mem_mb}m"
            "      -eoom;"
            "else"
            "  echo No unmapped reads found;"
            "  echo -n | bgzip --stdout > {output.fq1};"
            "  echo -n | bgzip --stdout > {output.fq2};"
            "fi;"


with Stage("index_taxonomy_vp") as S:
    rule vp_index_ncbi_taxonomy:
        """This rule loads the NCBI taxonomy, compiles it into a graph_tool
        tree and stores that tree in binary format. Loading the binary
        format tree is much faster than parsing the entire NCBI
        taxonomy from text files.

        The output file is added to the reference "NcbiTaxonomy".
        """
        message:
            "{:name:}: Creating graph tool binary format tree from NCBI taxonomy"
        input:
            ncbi_nodes = "{:prev:}/{:target:}.NCBI.nodes.dmp",
            ncbi_names = "{:prev:}/{:target:}.NCBI.names.dmp",
            ncbi_merged = "{:prev:}/{:target:}.NCBI.merged.dmp",
        output:
            "{:this:}/{target}.taxonomy.gt"
        log:
            "{:this:}/{target}.taxonomy.gt.log"
        benchmark:
            "benchmarks/{:name:}/{:this:}/{target}.txt"
        threads:
            1
        resources:
            mem="8g"
        params:
            taxonomy_prefix = lambda wc, input: input.ncbi_names[:-len("names.dmp")]
        conda:
            "virprof_py"
        shell:
            "exec >{log} 2>&1;"
            "{BIN}/virprof index-tree"
            "  --library graph_tool"
            "  --ncbi-taxonomy {params.taxonomy_prefix}"
            "  --out {output}"


with Stage("blastfilter_vp") as S:
    S.add_param("U", typ="int", name="min_unaligned_bp", default=0)
    S.doc("""This stage filters input FASTA based on BLAST hits to a
    contaminant database (e.g. host). Only sequences with at least
    Unnn basepairs not aligned to any sequence in the reference are
    passed through.""")

    rule vp_filter_blast:
        """Rule filtering individual FASTA file"""
        message:
            "{:name:}: Filtering contigs {output}"
        input:
            fasta  = "{:prev:}/{:target:}.fasta.gz",
            blast7 = "{:prev:}/{:target:}.blast7.gz"
        output:
            fasta  = "{:this:}/{target}.fasta.gz"
        log:
            "{:this:}/{target}.log"
        benchmark:
            "benchmarks/{:name:}/{:this:}/{target}.txt"
        threads:
            1
        resources:
            mem="8g"
        conda:
            "virprof_py"
        shell:"""
        exec >{log} 2>&1
        {BIN}/virprof filter-blast \
         --min-unaligned-bp {params.min_unaligned_bp} \
         --out {output.fasta} \
         --in-fasta {input.fasta} \
         --in-blast7 {input.blast7}
        """

    rule vp_filter_blast_all:
        """Collection target in case this is the end of the pipeline"""
        message:
            "Completed {:this:}"
        input:
            "{:this:}/{:targets:}.fasta.gz"
        output:
            touch("{:this:}/all_targets.stamp")


with Stage("blastbin_vp") as S:
    S.doc("""
    Creates bins from blast hits
    """)

    rule vp_blastbin:
        message:
            "{:name:}: Classifying {output.result}"
        input:
            coverage = "{:prev:}/{:target:}.coverage",
            blast7   = "{:prev:}/{:target:}.blast7.gz",
            taxonomy = "{:prev:}/{:target:}.taxonomy.gt",
        output:
            result   = "{:this:}/{target}.virus.csv",
            hits     = "{:this:}/{target}.hits.csv",
            features = "{:this:}/{target}.features.csv",
        log:
                         "{:this:}/{target}.log"
        benchmark:
            "benchmarks/{:name:}/{:this:}/{target}.blastbin.txt"
        params:
            coverage = lambda wc, input: " --in-coverage ".join(ensure_list(input.coverage)),
            cache_path = "feature_table_cache",
            ncbi_api_key = ""
        threads:
            1
        resources:
            mem="8g"
        conda:
            "virprof_py"
        shell:
            "exec >{log} 2>&1;"
            "{BIN}/virprof blastbin"
            " --out {output.result}"
            " --out-hits {output.hits}"
            " --out-features {output.features}"
            " --ncbi-taxonomy {input.taxonomy}"
            " --in-blast7 {input.blast7}"
            " --in-coverage {params.coverage}"
            " --cache-path {params.cache_path}"
            " --ncbi-api-key '{params.ncbi_api_key}'"

    rule vp_bins_to_rds:
        message:
            "{:name:}: Exporting bins to RDS"
        input:
            calls = "{:this:}/{target}.virus.csv",
            hits = "{:this:}/{target}.hits.csv",
            features  = "{:this:}/{target}.features.csv",
            bam = "{:prev:}/{:target:}.sorted.bam",
        output:
            rds = "{:this:}/{target}.vp.rds",
        log:
            "{:this:}/{target}.vp.rds.log"
        benchmark:
            "benchmarks/{:name:}/{:this:}/{target}.vp.rds.txt"
        threads:
            1
        resources:
            mem="8g"
        conda:
            "virprof_r"
        params:
            task = "create"
        script:
            "vpimport.R"


with Stage("scaffold_vp") as S:
    S.doc("""
    Creates pseudo genomes from blast bins and contigs
    """)
    rule vp_scaffold_fasta:
        message:
            "{:name:}: Scaffolding {output.fasta}"
        input:
            bins  = "{:prev:}/{target}.virus.csv",
            hits  = "{:prev:}/{target}.hits.csv",
            fasta = "{:prev:}/{:target:}.fasta.gz"
        output:
            fasta =  "{:this:}/{target}.fasta.gz",
            scaffolds = "{:this:}/{target}.scaffolds.csv"
        log:
            "{:this:}/{target}.bin.log"
        benchmark:
            "benchmarks/{:name:}/{:this:}/{target}.txt"
        threads:
            1
        resources:
            mem="8g"
        conda:
            "virprof_py"
        params:
            bin_by = "species",
            fasta_id_format = lambda wc: f"{wc.target}.{{sacc}} [bin={{bin_name}}] [bp={{bp}}]",
            max_fill_length = 50000,
        shell:
            "exec >{log} 2>&1;"
            "{BIN}/virprof export-fasta"
            " --in-bins {input.bins}"
            " --in-hits {input.hits}"
            " --in-fasta {input.fasta}"
            " --out {output.fasta}"
            " --out-scaffolds {output.scaffolds}"
            " --fasta-id-format '{params.fasta_id_format}'"
            " --scaffold"
            " --max-fill-length {params.max_fill_length}"
            " --bin-by {params.bin_by}"

    rule vp_scaffold_all:
        message:
            "Completed {:this:}"
        input:
            bins = "{:this:}/{:targets:}.fasta.gz"
        output:
            touch("{:this:}/all_targets.stamp")


with Stage("collect_vp") as S:
    S.doc("""
    Collects pipeline data into RDS format files
    """)
    rule vp_add_covdepth:
        message:
            "{:name:}: Adding scaffold coverage to RDS"
        input:
            scaffolds = "{:prev:}/{:target:}.scaffolds.csv",  ## FIXME: load this actually
            rds = "{:prev:}/{:target:}.vp.rds",
            bam = "{:prev:}/{:target:}.sorted.bam"
        output:
            rds = "{:this:}/{target}.vp.rds",
        log:
            "{:this:}/{target}.log"
        benchmark:
            "benchmarks/{:name:}/{:this:}/{target}.show_bins.txt"
        threads:
            1
        resources:
            mem="64g"
        conda:
            "virprof_r"
        params:
            task = "scaffold_depth"
        script:
            "vpimport.R"


with Stage("bin_vp") as S:
    S.doc("""Rearranges sequences from per-sample to per-bin fasta files""")
    S.add_param("", typ="choice", name="bin_by",
                value=['Species', 'Acc', 'Taxname'], default='Species')

    rule vp_bin_fasta_file_lists:
        message:
            "{:name:}: Collecting input files"
        input:
            calls  = "{:prev:}/{:target:}.virus.csv",
            fasta = "{:prev:}/{:target:}.fasta.gz",
        output:
            call_flist = temp("{:this:}/{target}.call_flist"),
            fasta_flist = temp("{:this:}/{target}.fasta_flist"),
        run:
            with open(output.call_flist, "w") as out:
                for call in input.calls:
                    print(call, file=out)
            with open(output.fasta_flist, "w") as out:
                for fasta in input.fasta:
                    print(fasta, file=out)
    localrules: vp_bin_fasta_file_lists

    checkpoint vp_bin_fasta:
        message:
            "{:name:}: Sorting sequences into bins {output.bins}"
        input:
            call_flist = "{:this:}/{target}.call_flist",
            fasta_flist = "{:this:}/{target}.fasta_flist",
        output:
            bins =  "{:this:}/{target}.binlist.txt",
            fasta =  "{:this:}/{target}.{:bin:}.fasta.gz",
        log:
            "{:this:}/{target}.bin.log"
        benchmark:
            "benchmarks/{:name:}/{:this:}/{target}.txt"
        threads:
            1
        resources:
            mem="8g"
        conda:
            "virprof_py"
        params:
            out_bins = "{:this:}/%s.fasta.gz",
            filter_lineage = "^Virus",
        shell:
            "exec >{log} 2>&1;"
            "ulimit -Sn 50000;"  # may need a lot of files
            "{BIN}/virprof find-bins"
            " --in-call-files {input.call_flist}"
            " --in-fasta-files {input.fasta_flist}"
            " --filter-lineage {params.filter_lineage}"
            " --bin-by {params.bin_by}"
            " --out {params.out_bins}"
            " --out-bins {output.bins}"

    rule vp_bin_fasta_all:
        message:
            "Completed {:this:}"
        input:
            bins = "{:this:}/{:targets:}.binlist.txt"
        output:
            touch("{:this:}/all_targets.stamp")


with Stage("summarize_vp") as S:
    rule vp_aggregate_classifications:
        message:
            "{:name:}: Creating virus summary {output.excel}"
        input:
            virushostdb="{:prev:}/virushostdb.tsv",
            calls="{:prev:}/{:target:}.virus.csv",
            coverages="{:prev:}/{:target:}.coverage",
            basecov="{:prev:}/{:target:}.basecov.bg",
            scaffolds="{:prev:}/{:target:}.scaffolds.csv",
            rnaseq_stats="{:prev:}/{:target:}.stats.rds",
        output:
            call_files=temp("{:this:}/{target}.call_flist"),
            coverage_files=temp("{:this:}/{target}.coverage_flist"),
            basecov_files=temp("{:this:}/{target}.basecov_flist"),
            scaffold_files=temp("{:this:}/{target}.scaffold_flist"),
            excel="{:this:}/{target}.pathogens.xlsx",
            rds="{:this:}/{target}.pathogens.rds",
        benchmark:
            "benchmarks/{:name:}/{:this:}/{target}.txt"
        log:
            "{:this:}/{target}.summary.log"
        params:
            calls       = lambda wc, input: "\n".join(input.calls),
            coverages   = lambda wc, input: "\n".join(input.coverages),
            basecov     = lambda wc, input: "\n".join(input.basecov),
            scaffolds   = lambda wc, input: "\n".join(input.scaffolds),
            csv_out     = "{:this:}/{target}.summary_%s.csv",
            filter_host = "Homo sapiens",
            min_bp      = 200,
            min_reads   = 3,
            project = "{:project:}",
            label = make_label,
            version = ymp.get_config()._config.userdata.virprof.version,
            pipeline = "{:this:}"
        threads:
            1
        resources:
            mem="8g"
        conda:
            "virprof_r"
        shell:
            "exec >{log} 2>&1;\n"
            "\n"
            "echo '{params.calls}' > {output.call_files};\n"
            "echo '{params.coverages}' > {output.coverage_files};\n"
            "echo '{params.basecov}' > {output.basecov_files};\n"
            "echo '{params.scaffolds}' > {output.scaffold_files};\n"
            "\n"
            "{BIN}/aggregate_classifications.R"
            "  --set-project {params.project}"
            "  --set-label {params.label}"
            "  --set-version {params.version}"
            "  --set-pipeline {params.pipeline}"
            "  --virushostdb '{input.virushostdb}'"
            "  --filter-host '{params.filter_host}'"
            "  --min-bp '{params.min_bp}'"
            "  --min-reads '{params.min_reads}'"
            "  --out-excel '{output.excel}'"
            "  --out-csv '{params.csv_out}'"
            "  --out-rds '{output.rds}'"
            "  --in-rnaseq-stats '{input.rnaseq_stats}'"
            "  --in-list {output.call_files}"
            "  --in-coverage-list {output.coverage_files}"
            "  --in-scaffold-list {output.scaffold_files}"
            "  --in-basecov-list {output.basecov_files};\n"
            "\n"


    localrules: vp_aggregate_genomes
    rule vp_aggregate_genomes:
        message:
            "{:name:}: Copying genome files to {:this:}"
        input:
            fasta = "{:prev:}/{:target:}.fasta.gz",
        output:
            genomes_dir = directory("{:this:}/{target}.genomes"),
        log:
            "{:this:}/{target}.genomes.log"
        shell:
            "exec >{log} 2>&1;"
            "mkdir -p {output.genomes_dir};"
            "for path in {input.fasta}; do"
            "  name=$(basename $path);"
            "  cp -v $path {output.genomes_dir}/$name;"
            "done;"

    rule vp_aggregate_rds:
        message:
            "{:name:}: Combining R data"
        input:
            rds = "{:prev:}/{:target:}.vp.rds"
        output:
            rds = "{:this:}/{target}.vp.rds"
        log:
            "{:this:}/{target}.vp.log"
        benchmark:
            "benchmarks/{:name:}/{:this:}/{target}.aggregate_rds.txt"
        threads:
            1
        resources:
            mem="128g"
        conda:
            "virprof_r"
        params:
            task = "combine"
        script:
            "vpimport.R"


with Stage("report_pathogen_vp") as S:
    localrules: vp_pathogen_report
    rule vp_pathogen_report:
        message: "Copying results to reports directory"
        input:
            "{:prev:}/{:target:}.pathogens.xlsx",
            directory("{:prev:}/{:target:}.genomes"),
            #"{:prev:}/{:target:}.vp.rds",
            "{:prev:}/multiqc_report.html",
            directory("{:prev:}/multiqc_report_data"),
        output:
            "{:this:}/{target}.pathogens.xlsx",
            directory("{:this:}/{target}.genomes"),
            #"{:this:}/{target}.vp.rds",
            "{:this:}/{target}.vp_multiqc_report.html",
            directory("{:this:}/{target}.vp_multiqc_report_data"),
        log:
            "{:this:}/{target}.log"
        benchmark:
            "benchmarks/{:name:}/{:this:}/{target}.txt"
        threads:
            1
        resources:
            mem = "50m"
        params:
            slack_hook  = "",  # should be trailing part of form xxx/xxx/xxx
            reporttpl   = "{:ensuredir.reports:}/{:project:}.$LABEL.$TYPE.%Y-%m-%d_%H-%M$EXT",
            project = "{:project:}",
            label = make_label,
            version = ymp.get_config()._config.userdata.virprof.version,
        shell:
            "exec >{log} 2>&1;"
            "SRCS=({input});"
            "DSTS=({output});"
            "MSG=\"New Pathogen (v{params.version}) results for \`{params.project}\`:\n\n\";"
            "LABEL={params.label};"
            "for i in \"${{!SRCS[@]}}\"; do"
            "  echo Copying ${{SRCS[i]}} to ${{DSTS[i]}};"
            "  cp -a ${{SRCS[i]}} ${{DSTS[i]}};"
            "  BASE=$(basename ${{DSTS[i]}});"
            "  SUFFIX=${{BASE#{wildcards.target}.}};"
            "  TYPE=${{SUFFIX%.*}};"
            "  EXT=${{SUFFIX#*.}};"
            "  if [ \"$TYPE\"a == \"$EXT\"a ]; then"
            "    EXT=;"
            "  else"
            "    EXT=\".$EXT\";"
            "  fi;"
            "  REPORT=$(date +{params.reporttpl});"
            "  echo Copying ${{SRCS[i]}} to $REPORT;"
            "  cp -a ${{SRCS[i]}} $REPORT;"
            "  MSG=\"$MSG\n- \`$REPORT\`\";"
            "done;"
            "if [ -n \"{params.slack_hook}\" ]; then"
            "  curl"
            "    --request POST"
            "    --header 'Content-type: application/json'"
            "    --data '{{\"text\":\"'\"$MSG\"'\"}}'"
            "    https://hooks.slack.com/services/{params.slack_hook};"
            "fi;"
