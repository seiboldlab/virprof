Env(name="virprof_r", base="bioconda",
    packages=[
        "r-magrittr",
        "r-dplyr",
        "r-readr",
        "r-purrr",
        "r-tidyr",
        "r-stringr",
        "r-fuzzyjoin",
        "r-tibble",
        "r-openxlsx",
        "r-optparse",
        "r-tidyverse",
        "r-patchwork",
        "r-ggrepel",
        "r-here",
        "bioconductor-iranges",
        "bedtools",
        "r-rentrez",
        "r-ggnewscale",
    ])

Env(name="virprof_py", base="bioconda",
    packages=[
        "python>=3.10",
        "graph-tool >=2.34",
        "biopython",
        "click",
        "tqdm",
        "networkx > 2",
        "requests",
    ])

BIN = srcdir("../bin/")

VPCFG = ymp.get_config()._config.userdata.virprof

with Stage("get_unmapped_vp") as S:
    S.require(
        data = [["bam"], ["salmon/aux_info/unmapped_names.txt"]],
        fq = [["R1.fq.gz", "R2.fq.gz"]],
    )
    rule vp_unmapped_from_bam:
        message:
            "{:name:}: {input.bam}"
        input:
            bam =  "{:prev:}/{target}.bam"
        output:
            fq1 = temp("{:this:}/{target}.{:pairnames[0]:}.fq.gz"),
            fq2 = temp("{:this:}/{target}.{:pairnames[1]:}.fq.gz"),
        log:
            "{:this:}/{target}.log"
        benchmark:
            "benchmarks/{:name:}/{:this:}/{target}.txt"
        threads:
            4
        resources:
            mem = "8g"
        params:
            f = 12,
            F = 0x900,
            G = 0,
        conda:
            "samtools"
        shell:
            "samtools fastq"
            " -1 {output.fq1}"
            " -2 {output.fq2}"
            " --threads {threads}"
            " -f {params.f}"
            " -F {params.F}"
            " -G {params.G}"
            " {input}"
            " 2>&1 >{log}"

    rule vp_unmapped_from_salmon:
        message:
            "{:name:}: {output.fq1} from Salmon unmapped names"
        input:
            fq1 = "{:prev:}/{target}.{:pairnames[0]:}.fq.gz",
            fq2 = "{:prev:}/{target}.{:pairnames[1]:}.fq.gz",
            unmapped = "{:prev:}/{target}.salmon/aux_info/unmapped_names.txt",
        output:
            fq1 = temp("{:this:}/{target}.{:pairnames[0]:}.fq.gz"),
            fq2 = temp("{:this:}/{target}.{:pairnames[1]:}.fq.gz"),
        log:
            "{:this:}/{target}.log"
        benchmark:
            "benchmarks/{:name:}/{:this:}/{target}.txt"
        threads:
            8
        resources:
            mem="120g" # 80g sufficed for <48GB/fq.gz
        params:
            pattern = "u"
        conda:
            "bbmap"
        shell:
            "exec >{log} 2>&1;"
            "echo Grabbing {params.pattern} from {input.unmapped};"
            "echo and extracting from {input.fq1} and {input.fq2};"
            "if grep -ql '{params.pattern}$' {input.unmapped}; then"
            "  grep '{params.pattern}$' {input.unmapped} |"
            "    cut -d' ' -f1 |"
            "    filterbyname.sh"
            "      -Xmx{resources.mem_mb}m"
            "      in={input.fq1}"
            "      in2={input.fq2}"
            "      out={output.fq1}"
            "      out2={output.fq2}"
            "      names=/dev/stdin"
            "      include=t"
            "      -Xmx{resources.mem_mb}m"
            "      -eoom;"
            "else"
            "  echo No unmapped reads found;"
            "  echo -n | bgzip --stdout > {output.fq1};"
            "  echo -n | bgzip --stdout > {output.fq2};"
            "fi;"


with Stage("index_taxonomy_vp") as S:
    rule vp_index_ncbi_taxonomy:
        """This rule loads the NCBI taxonomy, compiles it into a graph_tool
        tree and stores that tree in binary format. Loading the binary
        format tree is much faster than parsing the entire NCBI
        taxonomy from text files.

        The output file is added to the reference "NcbiTaxonomy".
        """
        message:
            "{:name:}: Creating graph tool binary format tree from NCBI taxonomy"
        input:
            ncbi_nodes = "{:prev:}/{:target:}.NCBI.nodes.dmp",
            ncbi_names = "{:prev:}/{:target:}.NCBI.names.dmp",
            ncbi_merged = "{:prev:}/{:target:}.NCBI.merged.dmp",
        output:
            "{:this:}/{target}.taxonomy.gt"
        log:
            "{:this:}/{target}.taxonomy.gt.log"
        benchmark:
            "benchmarks/{:name:}/{:this:}/{target}.txt"
        threads:
            1
        resources:
            mem="8g"
        params:
            taxonomy_prefix = lambda wc, input: input.ncbi_names[:-len("names.dmp")]
        conda:
            "virprof_py"
        shell:
            "exec >{log} 2>&1;"
            "{BIN}/virprof index-tree"
            "  --library graph_tool"
            "  --ncbi-taxonomy {params.taxonomy_prefix}"
            "  --out {output}"


with Stage("fastaqc_vp") as S:
    rule vp_fasta_qc:
        message:
            "{:name:}: Collecting contig QC data to {output}"
        input:
            fasta = "{:prev:}/{:target:}.fasta.gz",
        output:
            csv = "{:this:}/{target}.fasta.qc.csv",
        log:
            "{:this:}/{target}.fasta.qc.log",
        benchmark:
            "benchmarks/{:name:}/{:this:}/{target}.contig_qc.txt",
        params:
            entropy_k_sizes = "1,2,3,4,6,10",
            homopolymer_min_size = 5
        threads:
            1
        resources:
            mem="1g"
        conda:
            "virprof_py"
        shell:
            "exec >{log} 2>&1;"
            "{BIN}/virprof fasta-qc"
            " --in-fasta {input.fasta}"
            " --out-csv {output.csv}"
            " --entropy-k-sizes {params.entropy_k_sizes}"
            " --homopolymer-min-size {params.homopolymer_min_size}"


with Stage("blastfilter_vp") as S:
    S.add_param("U", typ="int", name="min_unaligned_bp", default=0)
    S.doc("""This stage filters input FASTA based on BLAST hits to a
    contaminant database (e.g. host). Only sequences with at least
    Unnn basepairs not aligned to any sequence in the reference are
    passed through.""")

    rule vp_filter_blast:
        """Rule filtering individual FASTA file"""
        message:
            "{:name:}: Filtering contigs {output}"
        input:
            fasta  = "{:prev:}/{:target:}.fasta.gz",
            blast7 = "{:prev:}/{:target:}.blast7.gz"
        output:
            fasta  = "{:this:}/{target}.fasta.gz"
        log:
            "{:this:}/{target}.log"
        benchmark:
            "benchmarks/{:name:}/{:this:}/{target}.txt"
        threads:
            1
        resources:
            mem="1g"
        conda:
            "virprof_py"
        shell:"""
        exec >{log} 2>&1
        {BIN}/virprof filter-blast \
         --min-unaligned-bp {params.min_unaligned_bp} \
         --out {output.fasta} \
         --in-fasta {input.fasta} \
         --in-blast7 {input.blast7}
        """

    rule vp_filter_blast_all:
        """Collection target in case this is the end of the pipeline"""
        message:
            "Completed {:this:}"
        input:
            "{:this:}/{:targets:}.fasta.gz"
        output:
            touch("{:this:}/all_targets.stamp")


with Stage("blastbin_vp") as S:
    S.doc("""
    Creates bins from blast hits
    """)

    rule vp_blastbin:
        message:
            "{:name:}: Classifying {output.result}"
        input:
            coverage = "{:prev:}/{:target:}.coverage",
            blast7   = "{:prev:}/{:target:}.blast7.gz",
            taxonomy = "{:prev:}/{:target:}.taxonomy.gt",
            fastaqc  = "{:prev:}/{:target:}.fasta.qc.csv",
        output:
            result   = "{:this:}/{target}.virus.csv",
            hits     = "{:this:}/{target}.hits.csv",
            features = "{:this:}/{target}.features.csv",
        log:
                       "{:this:}/{target}.log"
        benchmark:
            "benchmarks/{:name:}/{:this:}/{target}.blastbin.txt"
        params:
            coverage = lambda wc, input: " --in-coverage ".join(ensure_list(input.coverage)),
            fastaqc = lambda wc, input: " --in-fastaqc ".join(ensure_list(input.fastaqc)),
            cache_path = "feature_table_cache",
            ncbi_api_key = VPCFG.ncbi_api_key,
            chain_penalty = VPCFG.bin_chain_penalty,
            min_reads = VPCFG.bin_min_reads,
            max_pcthp = VPCFG.bin_max_pcthp,
            prefilter_contigs = "' --prefilter-contigs '".join(VPCFG.bin_prefilter_contigs),
            prefilter_hits = "' --prefilter-hits '".join(VPCFG.bin_prefilter_hits),
            exclude = "' --exclude '".join(VPCFG.bin_exclude_taxa),
        threads:
            1
        resources:
            mem="8g"
        conda:
            "virprof_py"
        shell:
            "exec >{log} 2>&1;"
            "{BIN}/virprof blastbin"
            " --out {output.result}"
            " --out-hits {output.hits}"
            " --out-features {output.features}"
            " --ncbi-taxonomy {input.taxonomy}"
            " --in-blast7 {input.blast7}"
            " --in-coverage {params.coverage}"
            " --in-fastaqc {params.fastaqc}"
            " --cache-path {params.cache_path}"
            " --ncbi-api-key '{params.ncbi_api_key}'"
            " --prefilter-contigs '{params.prefilter_contigs}'"
            " --prefilter-hits '{params.prefilter_hits}'"
            " --no-standard-excludes"
            " --exclude '{params.exclude}'"
            " --chain-penalty {params.chain_penalty}"
            " --min-read-count {params.min_reads}"
            " --max-pcthp {params.max_pcthp}"

    rule vp_bins_to_rds:
        message:
            "{:name:}: Exporting bins to RDS"
        input:
            calls = "{:this:}/{target}.virus.csv",
            hits = "{:this:}/{target}.hits.csv",
            features  = "{:this:}/{target}.features.csv",
            bam = "{:prev:}/{:target:}.sorted.bam",
        output:
            rds = "{:this:}/{target}.vp.rds",
        log:
            "{:this:}/{target}.vp.rds.log"
        benchmark:
            "benchmarks/{:name:}/{:this:}/{target}.vp.rds.txt"
        threads:
            1
        resources:
            mem="8g"
        conda:
            "virprof_r"
        params:
            task = "create"
        script:
            "vpimport.R"


with Stage("scaffold_vp") as S:
    S.doc("""
    Creates pseudo genomes from blast bins and contigs
    """)
    rule vp_scaffold_fasta:
        message:
            "{:name:}: Scaffolding {output.fasta}"
        input:
            bins  = "{:prev:}/{target}.virus.csv",
            hits  = "{:prev:}/{target}.hits.csv",
            fasta = "{:prev:}/{:target:}.fasta.gz"
        output:
            fasta =  "{:this:}/{target}.fasta.gz",
            scaffolds = "{:this:}/{target}.scaffolds.csv"
        log:
            "{:this:}/{target}.bin.log"
        benchmark:
            "benchmarks/{:name:}/{:this:}/{target}.txt"
        threads:
            1
        resources:
            mem="8g"
        conda:
            "virprof_py"
        params:
            bin_by = "species",
            fasta_id_format = lambda wc: f"{wc.target}.{{sacc}} [bin={{bin_name}}] [bp={{bp}}]",
            max_fill_length = 50000,
        shell:
            "exec >{log} 2>&1;"
            "{BIN}/virprof export-fasta"
            " --in-bins {input.bins}"
            " --in-hits {input.hits}"
            " --in-fasta {input.fasta}"
            " --out {output.fasta}"
            " --out-scaffolds {output.scaffolds}"
            " --fasta-id-format '{params.fasta_id_format}'"
            " --scaffold"
            " --max-fill-length {params.max_fill_length}"
            " --bin-by {params.bin_by}"

    rule vp_scaffold_all:
        message:
            "Completed {:this:}"
        input:
            bins = "{:this:}/{:targets:}.fasta.gz"
        output:
            touch("{:this:}/all_targets.stamp")


with Stage("collect_vp") as S:
    S.doc("""
    Collects pipeline data into RDS format files
    """)
    rule vp_add_covdepth:
        message:
            "{:name:}: Adding scaffold coverage to RDS"
        input:
            scaffolds = "{:prev:}/{:target:}.scaffolds.csv",  ## FIXME: load this actually
            rds = "{:prev:}/{:target:}.vp.rds",
            bam = "{:prev:}/{:target:}.sorted.bam"
        output:
            rds = "{:this:}/{target}.vp.rds",
        log:
            "{:this:}/{target}.log"
        benchmark:
            "benchmarks/{:name:}/{:this:}/{target}.show_bins.txt"
        threads:
            1
        resources:
            mem="64g"
        conda:
            "virprof_r"
        params:
            task = "scaffold_depth"
        script:
            "vpimport.R"


with Stage("bin_vp") as S:
    S.doc("""Rearranges sequences from per-sample to per-bin fasta files""")
    S.add_param("", typ="choice", name="bin_by",
                value=['Species', 'Acc', 'Taxname'], default='Species')

    rule vp_bin_fasta_file_lists:
        message:
            "{:name:}: Collecting input files"
        input:
            calls  = "{:prev:}/{:target:}.virus.csv",
            fasta = "{:prev:}/{:target:}.fasta.gz",
        output:
            call_flist = temp("{:this:}/{target}.call_flist"),
            fasta_flist = temp("{:this:}/{target}.fasta_flist"),
        run:
            with open(output.call_flist, "w") as out:
                for call in input.calls:
                    print(call, file=out)
            with open(output.fasta_flist, "w") as out:
                for fasta in input.fasta:
                    print(fasta, file=out)
    localrules: vp_bin_fasta_file_lists

    checkpoint vp_bin_fasta:
        message:
            "{:name:}: Sorting sequences into bins {output.bins}"
        input:
            call_flist = "{:this:}/{target}.call_flist",
            fasta_flist = "{:this:}/{target}.fasta_flist",
        output:
            bins =  "{:this:}/{target}.binlist.txt",
            fasta =  "{:this:}/{target}.{:bin:}.fasta.gz",
        log:
            "{:this:}/{target}.bin.log"
        benchmark:
            "benchmarks/{:name:}/{:this:}/{target}.txt"
        threads:
            1
        resources:
            mem="8g"
        conda:
            "virprof_py"
        params:
            out_bins = "{:this:}/%s.fasta.gz",
            filter_lineage = VPCFG.export_filter,
        shell:
            "exec >{log} 2>&1;"
            "ulimit -Sn 50000;"  # may need a lot of files
            "{BIN}/virprof find-bins"
            " --in-call-files {input.call_flist}"
            " --in-fasta-files {input.fasta_flist}"
            " --filter-lineage {params.filter_lineage}"
            " --bin-by {params.bin_by}"
            " --out {params.out_bins}"
            " --out-bins {output.bins}"

    rule vp_bin_fasta_all:
        message:
            "Completed {:this:}"
        input:
            bins = "{:this:}/{:targets:}.binlist.txt"
        output:
            touch("{:this:}/all_targets.stamp")


with Stage("summarize_vp") as S:
    rule vp_aggregate_classifications:
        message:
            "{:name:}: Creating virus summary {output.excel}"
        input:
            virushostdb="{:prev:}/virushostdb.tsv",
            calls="{:prev:}/{:target:}.virus.csv",
            coverages="{:prev:}/{:target:}.coverage",
            basecov="{:prev:}/{:target:}.basecov.bg",
            scaffolds="{:prev:}/{:target:}.scaffolds.csv",
            fastaqc="{:prev:}/{:target:}.fasta.qc.csv",
            rnaseq_stats="{:prev:}/{:target:}.stats.rds",
            whitelist=VPCFG.get_path("whitelist"),
        output:
            call_files=temp("{:this:}/{target}.call_flist"),
            coverage_files=temp("{:this:}/{target}.coverage_flist"),
            basecov_files=temp("{:this:}/{target}.basecov_flist"),
            scaffold_files=temp("{:this:}/{target}.scaffold_flist"),
            fastaqc_files=temp("{:this:}/{target}.fastaqc_flist"),
            excel="{:this:}/{target}.pathogens.xlsx",
            rds="{:this:}/{target}.pathogens.rds",
        benchmark:
            "benchmarks/{:name:}/{:this:}/{target}.txt"
        log:
            "{:this:}/{target}.summary.log"
        params:
            calls       = lambda wc, input: "\n".join(input.calls),
            coverages   = lambda wc, input: "\n".join(input.coverages),
            basecov     = lambda wc, input: "\n".join(input.basecov),
            scaffolds   = lambda wc, input: "\n".join(input.scaffolds),
            fastaqc     = lambda wc, input: "\n".join(input.fastaqc),
            csv_out     = "{:this:}/{target}.summary_%s.csv",
            filter_host = VPCFG.host_species,
            min_bp      = VPCFG.min_bp,
            min_aligned_bp = VPCFG.min_aligned_bp,
            min_reads   = VPCFG.min_reads,
            max_pcthp   = VPCFG.max_pcthp,
            project = "{:project:}",
            label = make_label,
            version = VPCFG.version,
            pipeline = "{:this:}"
        threads:
            1
        resources:
            mem="8g"
        conda:
            "virprof_r"
        shell:
            "exec >{log} 2>&1;\n"
            "\n"
            "echo '{params.calls}' > {output.call_files};\n\n"
            "echo '{params.coverages}' > {output.coverage_files};\n\n"
            "echo '{params.basecov}' > {output.basecov_files};\n\n"
            "echo '{params.scaffolds}' > {output.scaffold_files};\n\n"
            "echo '{params.fastaqc}' > {output.fastaqc_files};\n\n"
            "\n"
            "{BIN}/aggregate_classifications.R"
            "  --set-project {params.project}"
            "  --set-label {params.label}"
            "  --set-version {params.version}"
            "  --set-pipeline {params.pipeline}"
            "  --virushostdb '{input.virushostdb}'"
            "  --filter-host '{params.filter_host}'"
            "  --min-bp '{params.min_bp}'"
            "  --min-aligned-bp '{params.min_aligned_bp}'"
            "  --min-reads '{params.min_reads}'"
            "  --max-pcthp '{params.max_pcthp}'"
            "  --out-excel '{output.excel}'"
            "  --out-csv '{params.csv_out}'"
            "  --out-rds '{output.rds}'"
            "  --in-rnaseq-stats '{input.rnaseq_stats}'"
            "  --in-list {output.call_files}"
            "  --in-coverage-list {output.coverage_files}"
            "  --in-scaffold-list {output.scaffold_files}"
            "  --in-fastaqc-list {output.fastaqc_files}"
            "  --in-white-list {input.whitelist}"
            "  --in-basecov-list {output.basecov_files};\n"
            "\n"

    localrules: vp_aggregate_genomes
    rule vp_aggregate_genomes:
        message:
            "{:name:}: Copying genome files to {:this:}"
        input:
            fasta = "{:prev:}/{:target:}.fasta.gz",
        output:
            genomes_dir = directory("{:this:}/{target}.genomes"),
        log:
            "{:this:}/{target}.genomes.log"
        shell:
            "exec >{log} 2>&1;"
            "mkdir -p {output.genomes_dir};"
            "for path in {input.fasta}; do"
            "  name=$(basename $path);"
            "  cp -v $path {output.genomes_dir}/$name;"
            "done;"

    rule vp_aggregate_rds:
        message:
            "{:name:}: Combining R data"
        input:
            rds = "{:prev:}/{:target:}.vp.rds"
        output:
            rds = "{:this:}/{target}.vp.rds"
        log:
            "{:this:}/{target}.vp.log"
        benchmark:
            "benchmarks/{:name:}/{:this:}/{target}.aggregate_rds.txt"
        threads:
            1
        resources:
            mem="128g"
        conda:
            "virprof_r"
        params:
            task = "combine"
        script:
            "vpimport.R"


with Stage("report_pathogen_vp") as S:
    localrules: vp_pathogen_report
    rule vp_pathogen_report:
        message: "Copying results to reports directory"
        input:
            "{:prev:}/{:target:}.pathogens.xlsx",
            "{:prev:}/{:target:}.pathogens.rds",
            directory("{:prev:}/{:target:}.genomes"),
            #"{:prev:}/{:target:}.vp.rds",
            "{:prev:}/multiqc_report.html",
            directory("{:prev:}/multiqc_report_data"),
        output:
            "{:this:}/{target}.pathogens.xlsx",
            "{:this:}/{target}.pathogens.rds",
            directory("{:this:}/{target}.genomes"),
            #"{:this:}/{target}.vp.rds",
            "{:this:}/{target}.vp_multiqc_report.html",
            directory("{:this:}/{target}.vp_multiqc_report_data"),
        log:
            "{:this:}/{target}.log"
        benchmark:
            "benchmarks/{:name:}/{:this:}/{target}.txt"
        threads:
            1
        resources:
            mem = "50m"
        params:
            slack_hook  = VPCFG.slack_hook,
            reporttpl   = "{:ensuredir.reports:}/{:project:}.$LABEL.$TYPE.%Y-%m-%d_%H-%M$EXT",
            project = "{:project:}",
            label = make_label,
            version = VPCFG.version,
        shell:
            "exec >{log} 2>&1;"
            "SRCS=({input});"
            "DSTS=({output});"
            "MSG=\"New Pathogen (v{params.version}) results for \`{params.project}\`:\n\n\";"
            "LABEL={params.label};"
            "for i in \"${{!SRCS[@]}}\"; do"
            "  echo Copying ${{SRCS[i]}} to ${{DSTS[i]}};"
            "  cp -a ${{SRCS[i]}} ${{DSTS[i]}};"
            "  BASE=$(basename ${{DSTS[i]}});"
            "  SUFFIX=${{BASE#{wildcards.target}.}};"
            "  TYPE=${{SUFFIX%.*}};"
            "  EXT=${{SUFFIX#*.}};"
            "  if [ \"$TYPE\"a == \"$EXT\"a ]; then"
            "    EXT=;"
            "  else"
            "    EXT=\".$EXT\";"
            "  fi;"
            "  REPORT=$(date +{params.reporttpl});"
            "  echo Copying ${{SRCS[i]}} to $REPORT;"
            "  cp -a ${{SRCS[i]}} $REPORT;"
            "  MSG=\"$MSG\n- \`$REPORT\`\";"
            "done;"
            "if [ -n \"{params.slack_hook}\" ]; then"
            "  curl"
            "    --request POST"
            "    --header 'Content-type: application/json'"
            "    --data '{{\"text\":\"'\"$MSG\"'\"}}'"
            "    https://hooks.slack.com/services/{params.slack_hook};"
            "fi;"
