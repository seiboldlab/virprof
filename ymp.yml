# Projects run with the pipeline. Each has a single CSV
# defining units, samples and fastq file locations.
projects:
  covid:
    data: projects/covid.csv
  daps:
    data: projects/daps.csv
  enigma:
    data: projects/enigma.csv
  gala:
    data: projects/gala.csv
  hrvc15:
    data: projects/hrvc15.csv
  inspire:
    data: projects/inspire.csv
  sarp:
    data: projects/sarp.csv
  sunbeam:
    data: projects/sunbeam.csv
  test:
    data: projects/test.csv

pipelines:
  qc:
    stages:
      - qc_fastqc
      - trim_bbmapAQ10L70
      - qc_fastqc

  enrich:
    stages:
      - map_bbmapS
      - extract_readsG12

  deplete:
    stages:
      - map_hisat2
      - extract_readsf12
      - map_bowtie2
      - extract_readsf12

  assemble_single:
    stages:
      - group_sample
      - assemble_spadesSc
      - format_bbmapL200

  assemble_meta:
    stages:
      - dust_bbmapE60:
          hide: true
      - group_sample
      - assemble_spadesMeta
      - format_bbmapL200

  coverage:
    stages:
      - index_bowtie2
      - map_bowtie2S
      - sort_bam
      - coverage_samtools

  blastbin:
    stages:
      - ref_hg38
      - annotate_blastE2MegaBest
      - blastfilter_vpU200
      - ref_NT
      - annotate_blastE10Best
      - ref_NcbiTaxonomy
      - blastbin_vp

  # Reference guidedworkflow
  targeted:
    stages:
      - qc
      - enrich
      - assemble_single
      - coverage
      - blastbin

  generic:
    stages:
      - qc
      - ref_hg38
      - deplete
      - assemble_meta
      - coverage
      - blastbin

# Local cluster configuration:
cluster:
  # Which cluster engine profile to use
  profile: slurm
  profiles:
    slurm:
      args:
        # Add parameter selecting the queue
        queue: "-p normal"
    lsf:
      args:
        # Add parameter selecting the queue
        queue: "-q foo24"
    default:
      # Limit how many jobs we keep in the queue
      # (Note: This is jobs, not cores as the name would suggest)
      cluster_cores: 500
      # Limit the number of jobs submitted per second
      max_jobs_per_second: 5
      # Wait very long for files to appear. Our NFS can be
      # extremely slow to sync from node to node.
      latency_wait: 600


limits:
  # All jobs should request at least 8GB RAM.
  min_mem: 8G
  # Scale large jobs (mapping, assembly) down to the
  # max memory our regular compute nodes have available.
  max_mem: 256G


# Configure local references
references:
  # Human reference used for read and contig filtering:
  hg38:
    # The index files for Bowtie2
    - url:
        /data/reference/iGenomes/Homo_sapiens/UCSC/hg38/Sequence/Bowtie2Index/
      type: dirx
      files:
        ALL.1.bt2: genome.1.bt2
        ALL.2.bt2: genome.2.bt2
        ALL.3.bt2: genome.3.bt2
        ALL.4.bt2: genome.4.bt2
        ALL.rev.1.bt2: genome.rev.1.bt2
        ALL.rev.2.bt2: genome.rev.2.bt2
        ALL.fasta: genome.fa
    # The index files for Blast
    - url: /data/reference/iGenomes/Homo_sapiens/UCSC/hg38/Sequence/WholeGenomeFasta/
      type: dirx
      files:
        ALL.nin: genome_blastn.nin
        ALL.nhr: genome_blastn.nhr
        ALL.nsq: genome_blastn.nsq
        ALL.nsi: genome_blastn.nsi
        ALL.nsd: genome_blastn.nsd
        ALL.nog: genome_blastn.nog
    # The index files for Hisat2
    - url: /Seibold/data/Reference/HISAT/grch38_snp_tran/
      type: dirx
      files:
        ALL.1.ht2: genome_snp_tran.1.ht2
        ALL.2.ht2: genome_snp_tran.2.ht2
        ALL.3.ht2: genome_snp_tran.3.ht2
        ALL.4.ht2: genome_snp_tran.4.ht2
        ALL.5.ht2: genome_snp_tran.5.ht2
        ALL.6.ht2: genome_snp_tran.6.ht2
        ALL.7.ht2: genome_snp_tran.7.ht2
        ALL.8.ht2: genome_snp_tran.8.ht2
  # NCBI Nucleotide database for Blast
  NT:
    - url: /data/reference/NCBI_nt/NCBI_NT_2020-05-01/
      type: path
      group:
        - nt
      match:
        - (?P<sample>[^.]+)\.((nal|not|nto|ntf|nos|ndb)|[0-9]+\.(nin|nhr|nsq|nsd|nog))
  # NCBI Taxonomy dump for classification
  NcbiTaxonomy:
    - url: /data/reference/NCBI/taxonomy/
      type: dirx
      files:
        ALL.NCBI.nodes.dmp: nodes.dmp
        ALL.NCBI.names.dmp: names.dmp
  # SILVA databases for removing rRNA (unused at this time)
  SilvaSSU:
    - url: https://www.arb-silva.de/fileadmin/silva_databases/release_138/Exports/SILVA_138_SSURef_NR99_tax_silva_trunc.fasta.gz
  SilvaLSU:
    - url: https://www.arb-silva.de/fileadmin/silva_databases/release_132/Exports/SILVA_132_LSURef_tax_silva_trunc.fasta.gz
  hrvc:
    - url: data/hrv_c_15.fasta.gz
  scov2:
    - url: data/sars_cov_2.fasta.gz
  hrvpb:
    - url: data/hrv_pb_unaligned.fasta.gz
